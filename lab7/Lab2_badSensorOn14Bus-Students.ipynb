{"cells":[{"cell_type":"markdown","metadata":{"id":"YzQ8X1VZNhIt"},"source":["# Lab 2: Detecting Bad Sensors in Power System Monitoring\n","\n","In this lab, our goal is to detect bad sensor data measured on the IEEE 14 bus test\n","system shown below. The power flow equations that couple the voltages and power flows are \n","nonlinear in nature, as discussed in class. We will load the sensor data from the\n","file 'sensorData14Bus.csv', and utilize SVM to perform the bad data detection.\n","We aim to understand how various parameters such as the nature of the corrupt data,\n","the number of corrupt data, etc., affect our abilities to classify the data.\n","\n","<img src=\"IEEE14bus.png\">"]},{"cell_type":"markdown","metadata":{"id":"S0laArbiNhIz"},"source":["### First, we need to call the needed libraries"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1635112474577,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"cGCXZ9AxNhI0"},"outputs":[],"source":["import numpy as np\n","import os\n","from sklearn import preprocessing, svm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from IPython.display import Image\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"bN0NkfJHNhI2"},"source":["### Loading the data \n","\n","Load the sensor data from the IEEE 14 bus test system, that has 14 buses\n"," and 20 branches. The data has been generated by adding a small noise\n"," to feasible voltages and power flows.\n","     \n","     Columns 1-14 contain bus voltage magnitudes.\n","     \n","     Columns 15-28 contain bus voltage phase angles.\n","     \n","     Columns 29-48 contain real power flow on all branches.\n","     \n","     Columns 49-68 contain reactive power flow on all branches."]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1635112474743,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"Oe1TyDKLNhI4","outputId":"b20232f0-99ad-4726-a234-1bad6a83491d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded sensor data on IEEE 14 bus system.\n","Number of data points = 5000, number of features = 26\n"]}],"source":["nBuses = 14\n","nBranches = 20\n","\n","# Select the bus numbers you monitor. For convenience, we have selected it for you.\n","# The '-1' makes them columns as per Python's convention of starting to number\n","# from 0.\n","busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n","columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n","\n","# Select the branches that you monitor.\n","branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n","columnsForBranches = np.concatenate((branchesToSample + 28,\n","                                     branchesToSample + 48))\n","\n","# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n","# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n","# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n","# with each column typecast as 'np.float32'.\n","X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n","                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n","                  max_rows=5000)\n","\n","nDataPoints = np.shape(X)[0]\n","nFeatures = np.shape(X)[1]\n","\n","print(\"Loaded sensor data on IEEE 14 bus system.\")\n","print(\"Number of data points = %d, number of features = %d\"\n","      % (nDataPoints, nFeatures))"]},{"cell_type":"markdown","metadata":{"id":"4qkCELffNhI6"},"source":["### Curroption Models \n","\n","Intentionally corrupt the first 'nCorrupt' rows of the data by adding\n"," a quantity to one or two sensor measurements that is not representative of\n"," our error model. We aim to study what nature of corruption is easier\n"," or difficult to detect.\n"," Specifically, we shall study 3 different models:\n"," \n","     1. 'corruptionModel' = 1 : Add a random number with a bias to one of the measurements.\n","     \n","     2. 'corruptionModel' = 2 : Add a random number without bias to one of the measurements.\n","     \n","     3. 'corruptionModel' = 3 : Add a random number with a bias to both the measurements.\n","     \n","In all these cases, we will multiply the sensor data by either a uniform or a normal random number multiplied by 'multiplicationFactor'.\n"]},{"cell_type":"code","execution_count":99,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635112474743,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"jLH4dD5RNhI7"},"outputs":[],"source":["def corrupt(X, nCorrupt, corruptionModel, columnsToCorruptOption, busesToSample, branchesToSample):\n","    # Choose a corruption model.\n","    # nCorrupt = int(nDataPoints/3)\n","    # corruptionModel = 1\n","    multiplicationFactor = 0.5\n","\n","    # Choose which data to tamper with, that can be a voltage magnitude,\n","    # voltage phase angle, real power flow on a branch, reactive power flow\n","    # on a branch. We create functions to extract the relevant column to\n","    # corrupt the corresponding data in the 'ii'-th bus or branch.\n","    voltageMagnitudeColumn = lambda ii: ii\n","\n","    voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n","\n","    realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n","    reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n","\n","    # Encode two different kinds of columns to corrupt.\n","    # Option 1: Corrupt real power columns only.\n","    # Option 2: Corrupt real power and voltage magnitude.\n","    # columnsToCorruptOption = 2\n","\n","    if columnsToCorruptOption == 1:\n","        columnsToCorrupt = [realPowerColumn(1),\n","                            realPowerColumn(2)]\n","    else:\n","        columnsToCorrupt = [voltageMagnitudeColumn(0),\n","                            realPowerColumn(1)]\n","\n","    # Corrupt the data appropriately, given the options.\n","    for index in range(nCorrupt):\n","\n","        if corruptionModel == 1:\n","            X[index, columnsToCorrupt[0]] \\\n","                *= (1 + multiplicationFactor * np.random.rand())\n","        elif corruptionModel == 2:\n","            X[index, columnsToCorrupt[0]] \\\n","                *= (1 + multiplicationFactor * np.random.randn())\n","        else:\n","            X[index, columnsToCorrupt[0]] \\\n","                *= (1 + multiplicationFactor * np.random.rand())\n","            X[index, columnsToCorrupt[1]] \\\n","                *= (1 + multiplicationFactor * np.random.rand())\n","\n","nCorrupt = int(nDataPoints/3)\n","corrupt(X, nCorrupt, 1, 2, busesToSample, branchesToSample)"]},{"cell_type":"markdown","metadata":{"id":"SxYgnoaMNhI8"},"source":[" It is always a good practice to scale your data to run SVM. Notice that we are\n"," cheating a little when we scale the entire data set 'X', because our training and\n"," test sets are derived from 'X'. Ideally, one would have to scale the training\n"," and test sets separately. Create the appropriate labels and shuffle the lists 'X' and 'Y' together.\n"]},{"cell_type":"code","execution_count":100,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635112474744,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"ASUMLZ_ZNhI9"},"outputs":[],"source":["X = preprocessing.StandardScaler().fit_transform(X)\n","\n","# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n","# 0's for the rest.\n","Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n","\n","# Shuffle the features and the labels together.\n","XY = list(zip(X, Y))\n","np.random.shuffle(XY)\n","X, Y = zip(*XY)"]},{"cell_type":"markdown","metadata":{"id":"43miQ8N5NhI-"},"source":["Recall from the first lab that 'test_size' determines what fraction of the data becomes your test set.\n","\n","## Task 1 (10 points)\n","\n","Split the dataset into two parts: training and testing.\n","Store the training set in the variables 'trainX' and 'trainY'.\n"," Store the testing set in the variables 'testX' and 'testY.\n"," Reserve 20% of the data for testing.\n","The function 'train_test_split' may prove useful.\n"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635112474744,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"_UjW0EnoNhI_"},"outputs":[],"source":["# Enter your code here\n","trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)"]},{"cell_type":"markdown","metadata":{"id":"-Iwq1Dv6NhJA"},"source":["## Task 2 (10 points)\n","\n"," Define the support vector machine classifier and train on the variables 'trainX' and 'trainY'. Use the SVC library from sklearn.svm. Only specify three hyper-parameters: 'kernel', 'degree', and 'max_iter'. Limit the maximum number of iterations to 100000 at the most. Set the kernel to be a linear classifier first. You may have to change it to report the results with other kernels. The parameter 'degree' specifies the degree for polynomial kernels. This parameter is not used for other kernels. The functions 'svm.SVC' and 'fit' will prove useful.\n","\n"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385,"status":"ok","timestamp":1635112475124,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"JOanhIKlNhJB","outputId":"84d54ec9-9d80-459e-f519-fe5d1e79fda8"},"outputs":[{"data":{"text/plain":["SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n","    max_iter=100000, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["# Enter your code here\n","clf = svm.SVC(kernel='linear', max_iter=100000) # linear\n","# clf = svm.SVC(kernel='linear', degree=3, max_iter=100000) \n","clf.fit(trainX, trainY)"]},{"cell_type":"markdown","metadata":{"id":"to1HiuC-NhJB"},"source":["## Task 3 (10 points)\n","\n","Predict the labels on the 'testX' dataset and store them in 'predictY'.\n"]},{"cell_type":"code","execution_count":103,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1635112475125,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"E5qmF9TWNhJC"},"outputs":[],"source":["# Enter your code here\n","predictY = clf.predict(testX)"]},{"cell_type":"markdown","metadata":{"id":"DaiOtXgINhJC"},"source":["## Task 4 (10 points)\n","\n","Print the 'classification_report' to see how well 'predictY' matches with 'testY'.\n"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1635112475126,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"hjPFHBwgNhJD","outputId":"783b3f33-1a03-4b53-a78f-100875f8bb15"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.98      1.00      0.99       651\n","         1.0       1.00      0.96      0.98       349\n","\n","    accuracy                           0.99      1000\n","   macro avg       0.99      0.98      0.98      1000\n","weighted avg       0.99      0.99      0.99      1000\n","\n"]}],"source":["# Enter your code here\n","print(classification_report(testY, predictY))"]},{"cell_type":"markdown","metadata":{"id":"HvHhlQ7INhJD"},"source":["Print svm's internal accuracy score as a percentage."]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1635112475127,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"V_NJv-7RNhJD","outputId":"713ca8bb-5b7f-4066-bf29-59afe7e4cee6"},"outputs":[{"name":"stdout","output_type":"stream","text":["svm's internal accuracy score = 98.6 %\n"]}],"source":["# Enter your code here\n","print(f'svm\\'s internal accuracy score = {clf.score(testX, testY) * 100.0} %')"]},{"cell_type":"markdown","metadata":{"id":"Le8_v2z5NhJE"},"source":["## Task 5\n","\n","We would like to compare 'classification_report' with this score for various runs. Let us consider the following cases: \n","\n","### Case 1:\n","\n","Only have sensor measurements from the first 5 branches. Choose option 1 in the 'columnsToCorruptOption'. Examine how well linear kernels perform when 'corruptionModel' = 1, 'corruptionModel' = 2, and 'corruptionModel'= 3. In case linear kernels do not perform well, you may try 'rbf' or polynomial kernels with degree 2.\n","\n","### Case 2:\n","\n","Choose 'corruptionModel = 1' with 'linear' kernel. Does it pay to monitor voltage magnitudes than power flows? In other words, do you consistently get better results when you choose 'columnsToCorruptOption' as 2? Make these judgements using the average score of at least 5 runs.\n","\n","\n","#### Your task is to investigate the above two cases. You may add a few 'Markdown' and 'Code' cells below with your comments, code, and results. You can also report your results as a pandas DataFrame. You are free to report your results in your own way."]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1635112475127,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"2dz2v-vMNhJE"},"outputs":[],"source":["def preprocess(X, Y, nCorrupt):\n","    X = preprocessing.StandardScaler().fit_transform(X)\n","\n","    # Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n","    # 0's for the rest.\n","    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n","\n","    # Shuffle the features and the labels together.\n","    XY = list(zip(X, Y))\n","    np.random.shuffle(XY)\n","    X, Y = zip(*XY)\n","\n","    return X, Y"]},{"cell_type":"markdown","metadata":{"id":"5qSihRW_NhJF"},"source":["## case1\n","Model3 performs the best. I guess this is because the error are posed to both measurements instead of only one. Thus, the model can detect the corruption easier.\n","Model2 performs the worst. I guess random error without bias can be the hardest case to detect due to its irregularity.\n","\n"]},{"cell_type":"code","execution_count":107,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2176,"status":"ok","timestamp":1635112477297,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"33toaGInNhJF","outputId":"45f6128b-7988-4b75-8ad8-a73a796a1456"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","corruptionModel = 1\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      1.00      0.97       678\n","         1.0       1.00      0.85      0.92       322\n","\n","    accuracy                           0.95      1000\n","   macro avg       0.97      0.93      0.94      1000\n","weighted avg       0.95      0.95      0.95      1000\n","\n","svm's internal accuracy score = 95.19999999999999 %\n","\n","corruptionModel = 2\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      1.00      0.90       670\n","         1.0       0.99      0.54      0.70       330\n","\n","    accuracy                           0.85      1000\n","   macro avg       0.90      0.77      0.80      1000\n","weighted avg       0.87      0.85      0.83      1000\n","\n","svm's internal accuracy score = 84.6 %\n","\n","corruptionModel = 3\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      1.00      0.97       694\n","         1.0       1.00      0.84      0.91       306\n","\n","    accuracy                           0.95      1000\n","   macro avg       0.97      0.92      0.94      1000\n","weighted avg       0.96      0.95      0.95      1000\n","\n","svm's internal accuracy score = 95.19999999999999 %\n"]}],"source":["for model in [1, 2, 3]:\n","    # sensor measurements from the first 5 braches\n","    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n","    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n","\n","    branchesToSample = np.array([1, 2, 3, 4, 5]) - 1\n","    columnsForBranches = np.concatenate((branchesToSample + 28,\n","                                        branchesToSample + 48))\n","\n","    # load data accordingly\n","    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n","                        usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n","                        max_rows=5000)\n","    nDataPoints = np.shape(X)[0]\n","    nFeatures = np.shape(X)[1]\n","\n","\n","    # corrupt\n","    nCorrupt = int(nDataPoints/3)\n","    corrupt(X, nCorrupt, model, 1, busesToSample, branchesToSample)\n","\n","    # prepare for training\n","    X, Y = preprocess(X, Y, nCorrupt)\n","    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n","\n","    clf = svm.SVC(kernel='rbf', max_iter=100000) # linear\n","    clf.fit(trainX, trainY)\n","\n","    predictY = clf.predict(testX)\n","    print(f'\\ncorruptionModel = {model}')\n","    print(classification_report(testY, predictY)) # if wish to see the clf report uncommented this line\n","    print(f'svm\\'s internal accuracy score = {clf.score(testX, testY) * 100.0} %')\n"]},{"cell_type":"markdown","metadata":{"id":"yPXbOnXRNhJG"},"source":["## case2\n","After 5 runs, the average performance of the option2 is significantly better than option1. This means more kinds of corruption can make error detection easier."]},{"cell_type":"code","execution_count":108,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18761,"status":"ok","timestamp":1635112496055,"user":{"displayName":"Jack Chiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16871214550012480344"},"user_tz":300},"id":"GtlRChPVNhJG","outputId":"0350318f-8d39-41fd-ff4f-7702bae0fdff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sensor measurements only from the first 5 braches(same as in case1)\n","Model: clf = svm.SVC(kernel='linear', max_iter=100000)\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n"]},{"name":"stdout","output_type":"stream","text":["columnsToCorruptOption = 1\n","svm's average score = 74.12 %\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  % self.max_iter, ConvergenceWarning)\n"]},{"name":"stdout","output_type":"stream","text":["columnsToCorruptOption = 2\n","svm's average score = 97.29 %\n","\n"]}],"source":["print('Sensor measurements only from the first 5 braches(same as in case1)')\n","print('Model: clf = svm.SVC(kernel=\\'linear\\', max_iter=100000)\\n')\n","\n","nRuns = 5\n","for opt in [1, 2]:\n","      score = 0\n","      for i in range(nRuns):\n","            # sensor measurements from the first 5 braches\n","            busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n","            columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n","\n","            branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n","            columnsForBranches = np.concatenate((branchesToSample + 28, branchesToSample + 48))\n","\n","            # load data accordingly\n","            X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n","                              usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n","                              max_rows=5000)\n","            nDataPoints = np.shape(X)[0]\n","            nFeatures = np.shape(X)[1]\n","\n","            # corrupt\n","            nCorrupt = int(nDataPoints/3)\n","            corrupt(X, nCorrupt, 1, opt, busesToSample, branchesToSample)\n","\n","            # prepare for training\n","            X, Y = preprocess(X, Y, nCorrupt)\n","            trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n","\n","            clf = svm.SVC(kernel='linear', max_iter=100000) # linear\n","            clf.fit(trainX, trainY)\n","\n","            predictY = clf.predict(testX)\n","            # print(classification_report(testY, predictY)) # if wish to see the clf report uncommented this line\n","            score += clf.score(testX, testY)\n","      \n","      print(f'columnsToCorruptOption = {opt}')\n","      print(f'svm\\'s average score = {score/nRuns*100:.2f} %\\n')\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Lab2_badSensorOn14Bus-Students.ipynb","provenance":[]},"interpreter":{"hash":"27defd6a9865291880d7e631815b086a7169dc7f77c3e63a734619a5bdb9440c"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
